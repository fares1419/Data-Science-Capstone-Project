{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520b479e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f3232",
   "metadata": {},
   "source": [
    "The goal of this project is to build a machine learning model that can predict the stock prices of companies listed on the Saudi Stock Exchange (Tadawul). The dataset used in this project is obtained from Kaggle and contains daily historical stock prices for various companies traded on the Tadawul from 2017 to 2020.\n",
    "\n",
    "The project will involve the following steps:\n",
    "\n",
    "Data cleaning and preprocessing: This step will involve cleaning the data, handling missing values, and converting categorical variables into numerical ones using techniques such as one-hot encoding or label encoding.\n",
    "\n",
    "Feature engineering: This step will involve creating new features from the existing data that may be useful in predicting stock prices. For example, we could create a feature that captures the trend of stock prices over a given period of time.\n",
    "\n",
    "Model training: This step will involve selecting an appropriate machine learning algorithm, such as linear regression or a neural network, and training it on the preprocessed and engineered dataset.\n",
    "\n",
    "Model evaluation: This step will involve evaluating the performance of the trained model on a held-out test set using appropriate metrics such as mean squared error or mean absolute error.\n",
    "\n",
    "Model deployment: Finally, we will deploy the trained model as a web application that allows users to input data about a particular company and get a predicted stock price as output.\n",
    "\n",
    "By building this model and deploying it as a web application, we can provide users with a convenient tool for predicting the stock prices of companies listed on the Tadawul. This could be useful for investors and traders who are looking for insights into the future performance of different companies in the market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26cbbe",
   "metadata": {},
   "source": [
    "# Problem Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e09f985",
   "metadata": {},
   "source": [
    "The problem domain of the project is to predict the close stock price for a given trading company based on historical stock data, as well as other relevant factors such as year, month, and day. The goal is to build a machine learning model that can accurately predict future stock prices, which can be used by investors to make informed investment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacedde",
   "metadata": {},
   "source": [
    "# The problem and solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d95b6b",
   "metadata": {},
   "source": [
    "The project aims to solve the problem of predicting the stock prices of companies listed in the Saudi Arabian stock market, Tadawul. The main challenge in this project is to develop an accurate machine learning model that can predict the stock prices based on a given set of features, such as trading name, open value, year, month, and day. The expected solution is to develop a web application that takes these features as input and outputs the predicted stock price for the corresponding trading name on the given date. To achieve this, a machine learning model will be developed and trained on historical data obtained from the Tadawul website. The model will be evaluated using metrics such as Mean Squared Error (MSE). Once the model is satisfactory, it will be integrated into a web application using Flask, HTML, and CSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca4506",
   "metadata": {},
   "source": [
    "# Load and Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(r\"C:\\Users\\faris\\Data-Science-Capstone-Project\\Tadawul_stcks.csv\")\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\فارس الدباسي\\Final Project\\Tadawul_stcks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd826b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #Checking null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f24764f",
   "metadata": {},
   "source": [
    "There are few nulls (compare to whole data) so it can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delte space from column name\n",
    "df.rename(columns = {'trading_name ':'trading_name','no_trades ':'no_trades'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48536f3",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03451042",
   "metadata": {},
   "source": [
    "How many companies in Saudi stucks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.trading_name.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cca82d",
   "metadata": {},
   "source": [
    "Which the highest close price in saudi stucks? and for which company?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['close'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['close']==df['close'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf=df.groupby(by='trading_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf['perc_Change']=sorteddf['perc_Change']*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926a87e",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4918445",
   "metadata": {},
   "source": [
    "Categorized to high risk and low risk based on percentage Change\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf['Risk']=[\"High\" if a>0 else \"low\" for a in sorteddf['perc_Change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd26c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d35fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf.Risk.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1837cd9",
   "metadata": {},
   "source": [
    "The highest change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cd7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf[sorteddf['perc_Change']==sorteddf.perc_Change.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658cdd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddf.perc_Change.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb02065",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_perc_Change=sorteddf.nlargest(5, 'perc_Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953712f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_perc_Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_names=list(top_5_perc_Change.index)\n",
    "top_5_close=list(top_5_perc_Change.change)\n",
    "top_5_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "colors = plt.cm.Set2(range(len(top_5_close)))\n",
    "\n",
    "plt.bar(top_5_names, top_5_close,color=colors)\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Top 5 percent Change Companies')\n",
    "plt.xlabel('Names')\n",
    "plt.ylabel('Close Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1326140",
   "metadata": {},
   "source": [
    "Stock Price over time fot the top 5 comapnies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4dc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "condition = df[\"trading_name\"].isin(top_5_names)\n",
    "selected_rows = df[condition]\n",
    "\n",
    "for _, company in selected_rows.groupby('trading_name'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(company['date'], company['close'])\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Closing Price')\n",
    "    ax.set_title(f'Stock Price for {company.iloc[0][\"trading_name\"]}')\n",
    "    plt.show()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e044c",
   "metadata": {},
   "source": [
    "# ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38aa1d",
   "metadata": {},
   "source": [
    "Machine learning model takes ('trading_name', 'date', 'open') and predict close ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ff98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a new dataframe with the encoded categorical variables\n",
    "new_df = df[['trading_name', 'date', 'open', 'close']].copy()\n",
    "\n",
    "# Encode the 'trading_name' column\n",
    "trading_name_encoder = LabelEncoder()\n",
    "new_df['trading_name'] = trading_name_encoder.fit_transform(new_df['trading_name'])\n",
    "\n",
    "# Convert the 'date' column to datetime format and extract year, month, and day as separate columns\n",
    "new_df['date'] = pd.to_datetime(new_df['date'])\n",
    "new_df['year'] = new_df['date'].dt.year\n",
    "new_df['month'] = new_df['date'].dt.month\n",
    "new_df['day'] = new_df['date'].dt.day\n",
    "\n",
    "# Drop the original 'date' column\n",
    "new_df = new_df.drop('date', axis=1)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = new_df[['trading_name', 'open', 'year', 'month', 'day']]\n",
    "y = new_df['close']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=LinearRegression()\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe773e",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e336222",
   "metadata": {},
   "source": [
    "The MSE has the advantage of being differentiable, which means that it can be used as a loss function during model training. This allows the model to be optimized using gradient descent or other optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04542248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "# Evaluate the model performance\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "mse2 = mean_squared_error(y_test, y_pred2)\n",
    "\n",
    "print('Mean squared error for model 1:', mse)\n",
    "\n",
    "print('Mean squared error for model 2:', mse2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7082f9a",
   "metadata": {},
   "source": [
    "Random forest works better than linear regression because it can handle non-linear relationships between features and target variable, can work with high-dimensional data, and is less prone to overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a14fb",
   "metadata": {},
   "source": [
    "# Compare betweem models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4660f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = ['Linear Regression', 'Random Forest']\n",
    "mse_values = [mse, mse2]\n",
    "\n",
    "plt.bar(models, mse_values)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Comparison of Linear Regression and Random Forest models')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c07fc7",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46693aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f101c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model in a pkl file\n",
    "with open('C:\\\\Users\\\\فارس الدباسي\\Final Project\\model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b4eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\فارس الدباسي\\Final Project\\le.pkl', 'wb') as file:\n",
    "    pickle.dump(le, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e507cd",
   "metadata": {},
   "source": [
    "# The process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1cf6b8",
   "metadata": {},
   "source": [
    "The process for which metrics, algorithms, and techniques were implemented with the given dataset has been thoroughly documented. In this project, the linear regression algorithm was implemented to predict stock prices. The dataset was preprocessed, including removing unnecessary columns and handling missing values. The remaining columns were then transformed using LabelEncoder() to convert categorical data to numerical data.\n",
    "\n",
    "The linear regression algorithm was then trained on the training set, and predictions were made on the testing set. The Mean Squared Error (MSE) metric was used to evaluate the performance of the model. The MSE value obtained was 11, which indicates a good performance of the model.\n",
    "\n",
    "Complications that occurred during the coding process included the handling of missing values and the selection of the appropriate algorithm. Several algorithms were tested before settling on linear regression, including random forest and support vector regression. However, linear regression was chosen due to its simplicity and good performance on this particular dataset.\n",
    "\n",
    "Overall, the process for implementing linear regression with the given dataset was successful and achieved good results in predicting stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214aa7",
   "metadata": {},
   "source": [
    "# Complications that occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca57c4",
   "metadata": {},
   "source": [
    "During the implementation of the linear regression model, one complication that occurred was the presence of missing data in the dataset. Since linear regression does not work well with missing values, it was decided to remove the missing rows from the dataset instead of imputing them with mean or median values. Another complication was the need to encode categorical variables, such as the trading name, into numerical values using the LabelEncoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45898cd",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb2c7e",
   "metadata": {},
   "source": [
    "Cleaned the dataset from the nulls value, and categorized comapnues to high risk and low risk to make the investor select the investment risk he want.\n",
    "Then build ML model (linear regression) that give it trading name, date, and open price of company the it will predict the close price with R2 score= 0.99! \n",
    "All of that in website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36633d83",
   "metadata": {},
   "source": [
    " I can say that one interesting aspect of this project is the use of financial data to predict stock prices, which requires a good understanding of finance and statistical modeling. Additionally, implementing hyperparameter tuning for the random forest model to improve its performance can be challenging, as it requires selecting the appropriate range of hyperparameters to search and evaluating the model's performance for each combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c12292",
   "metadata": {},
   "source": [
    "## Business Impact:\n",
    "Now, my model can tell you what is the close price for the company you ask, and that will make you more confident about if you buy or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5831d28",
   "metadata": {},
   "source": [
    "## Project Reflection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf2f92",
   "metadata": {},
   "source": [
    "From this project I have learned how to select dataset then clean and build model for it using pandas and sklearn, then show it in web by flask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925d028",
   "metadata": {},
   "source": [
    "## Future Work:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53f5b2",
   "metadata": {},
   "source": [
    "This project could have been improved by:\n",
    "\n",
    "- builiding power model by deep learning to avoid overfit.\n",
    "- devide the companies to more categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34711793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": true,
   "vp_note_width": 263,
   "vp_position": {
    "width": 541
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
